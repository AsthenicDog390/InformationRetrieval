{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Information Retrieval Evaluation Pipeline\n",
    "This notebook provides a template for evaluating query reformulation techniques using PyTerrier.\n",
    "Pipeline stages: Dataset Loading → Preprocessing → Query Reformulation → Retrieval → Evaluation\n",
    "\n"
   ],
   "id": "753a05bdc7331ed0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Dataset Loading\n",
    "This can be switched with another dataset, possibly requiring conversion to this format.\n"
   ],
   "id": "cd5d3d067a6d763"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T17:34:25.084549Z",
     "start_time": "2025-03-25T17:34:24.947793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "from pathlib import Path\n",
    "\n",
    "class DatasetComponents:\n",
    "    \"\"\"Container for dataset components that must be provided\"\"\"\n",
    "    def __init__(self, corpus_iter, queries_df, qrels_df):\n",
    "        self.corpus_iter = corpus_iter  # Iterator yielding {'docno': str, 'text': str}\n",
    "        self.queries_df = queries_df    # DataFrame with columns ['qid', 'query']\n",
    "        self.qrels_df = qrels_df        # DataFrame with columns ['qid', 'docno', 'label']\n",
    "\n",
    "def load_pt_dataset() -> DatasetComponents:\n",
    "    \"\"\"Load dataset using PyTerrier's built-in loader\"\"\"\n",
    "    dataset = pt.get_dataset(\"irds:antique/test/non-offensive\")\n",
    "\n",
    "    return DatasetComponents(\n",
    "        corpus_iter=dataset.get_corpus_iter(),\n",
    "        queries_df=dataset.get_topics(),\n",
    "        qrels_df=dataset.get_qrels()\n",
    "    )\n",
    "\n",
    "# Load the dataset\n",
    "data = load_pt_dataset()"
   ],
   "id": "db121cb9c9ddcc18",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "antique/test/non-offensive documents:   0%|          | 0/403666 [00:00<?, ?it/s]\u001B[A"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Preprocessing Pipeline\n",
    "Currently, this does no preprocessing."
   ],
   "id": "1d6430c8a33bc386"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T17:34:25.177075Z",
     "start_time": "2025-03-25T17:34:25.159836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Placeholder for text preprocessing logic\"\"\"\n",
    "    return text\n",
    "\n",
    "def preprocess_corpus(corpus_iter):\n",
    "    \"\"\"Generator that applies preprocessing to each document\"\"\"\n",
    "    for doc in corpus_iter:\n",
    "        yield {\n",
    "            'docno': doc['docno'],\n",
    "            'text': preprocess_text(doc['text'])\n",
    "        }\n",
    "\n",
    "def preprocess_queries(queries_df):\n",
    "    \"\"\"Apply preprocessing to queries dataframe\"\"\"\n",
    "    queries_df = queries_df.copy()\n",
    "    queries_df['query'] = queries_df['query'].apply(preprocess_text)\n",
    "    return queries_df\n",
    "\n",
    "# Apply preprocessing while maintaining iterator\n",
    "preprocessed_corpus = preprocess_corpus(data.corpus_iter)\n",
    "preprocessed_queries = preprocess_queries(data.queries_df)"
   ],
   "id": "ad9172b403521b3e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "antique/test/non-offensive documents:   0%|          | 0/403666 [16:42<?, ?it/s]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Query Reformulation",
   "id": "883dae17c944c37e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T17:34:25.219182Z",
     "start_time": "2025-03-25T17:34:25.204449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reformulate_queries(queries_df):\n",
    "    \"\"\"Placeholder for query reformulation techniques\"\"\"\n",
    "    modified_queries = queries_df.copy()\n",
    "    # Placeholder for actual reformulation\n",
    "    return modified_queries\n",
    "\n",
    "reformulated_queries = reformulate_queries(preprocessed_queries)"
   ],
   "id": "8cdc0163f153be40",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Indexing Pipeline",
   "id": "f56384466c733ca6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T17:34:25.434424Z",
     "start_time": "2025-03-25T17:34:25.241470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index_path = Path.cwd() / \"index\"\n",
    "index_ref = None\n",
    "\n",
    "# Check if valid index exists\n",
    "if (index_path / \"data.properties\").exists():\n",
    "    try:\n",
    "        index_ref = pt.IndexFactory.of(str(index_path))\n",
    "        print(f\"Loaded existing index from {index_path}\")\n",
    "\n",
    "        # Verify index contains documents\n",
    "        if index_ref.getCollectionStatistics().getNumberOfDocuments() == 0:\n",
    "            raise ValueError(\"Empty index - will rebuild\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Index loading failed ({str(e)}), rebuilding...\")\n",
    "        import shutil\n",
    "        shutil.rmtree(index_path)\n",
    "        index_ref = None\n",
    "\n",
    "# Build new index if needed\n",
    "if index_ref is None:\n",
    "    print(\"Building new index...\")\n",
    "    index_ref = pt.index.IterDictIndexer(\n",
    "        str(index_path),\n",
    "        meta={\"docno\": 32, \"text\": 131072},\n",
    "        type=pt.index.IndexingType.CLASSIC\n",
    "    ).index(preprocessed_corpus)\n",
    "    print(f\"Built new index at {index_path}\")\n",
    "\n",
    "# Verify index\n",
    "stats = index_ref.getCollectionStatistics()\n",
    "print(f\"Index contains {stats.getNumberOfDocuments()} documents\")"
   ],
   "id": "14c6f38522030fbc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing index from C:\\Users\\thein\\OneDrive\\Documents\\InformationRetrieval\\llm-query-rewriting\\index\n",
      "Index contains 403666 documents\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Retrieval Setup\n",
    "Currently, using BM25 for retrieval."
   ],
   "id": "6500474760e53a52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T17:34:25.467558Z",
     "start_time": "2025-03-25T17:34:25.457846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bm25 = pt.BatchRetrieve(\n",
    "    index_ref,\n",
    "    wmodel=\"BM25\",\n",
    "    metadata=[\"docno\", \"text\"],\n",
    "    properties={\"termpipelines\": \"\"},\n",
    "    controls={\"qe\": \"off\"}\n",
    ")"
   ],
   "id": "cf327eb8457b516",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thein\\AppData\\Local\\Temp\\ipykernel_9580\\2758154324.py:1: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  bm25 = pt.BatchRetrieve(\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Evaluation Pipeline",
   "id": "9acbe90722ed77a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T17:35:35.073117Z",
     "start_time": "2025-03-25T17:34:25.488041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run evaluation experiment\n",
    "# metrics: https://pyterrier.readthedocs.io/en/latest/experiments.html#available-evaluation-measures\n",
    "eval_metrics = [\"map\", \"ndcg_cut_10\", \"P_10\", \"recall_100\", \"recip_rank\"]\n",
    "\n",
    "results = pt.Experiment(\n",
    "    [bm25],\n",
    "    reformulated_queries,\n",
    "    data.qrels_df,\n",
    "    eval_metrics,\n",
    "    names=[\"BM25 Baseline\"],\n",
    "    baseline=0\n",
    ")\n",
    "\n",
    "results"
   ],
   "id": "d164eee1c656fe26",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            name       map  recip_rank      P_10  recall_100  ndcg_cut_10  \\\n",
       "0  BM25 Baseline  0.457005    0.938873  0.753977    0.657961     0.516219   \n",
       "\n",
       "  map + map - map p-value recip_rank +  ... recip_rank p-value P_10 + P_10 -  \\\n",
       "0  None  None        None         None  ...               None   None   None   \n",
       "\n",
       "  P_10 p-value recall_100 + recall_100 - recall_100 p-value ndcg_cut_10 +  \\\n",
       "0         None         None         None               None          None   \n",
       "\n",
       "  ndcg_cut_10 - ndcg_cut_10 p-value  \n",
       "0          None                None  \n",
       "\n",
       "[1 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>P_10</th>\n",
       "      <th>recall_100</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>map +</th>\n",
       "      <th>map -</th>\n",
       "      <th>map p-value</th>\n",
       "      <th>recip_rank +</th>\n",
       "      <th>...</th>\n",
       "      <th>recip_rank p-value</th>\n",
       "      <th>P_10 +</th>\n",
       "      <th>P_10 -</th>\n",
       "      <th>P_10 p-value</th>\n",
       "      <th>recall_100 +</th>\n",
       "      <th>recall_100 -</th>\n",
       "      <th>recall_100 p-value</th>\n",
       "      <th>ndcg_cut_10 +</th>\n",
       "      <th>ndcg_cut_10 -</th>\n",
       "      <th>ndcg_cut_10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25 Baseline</td>\n",
       "      <td>0.457005</td>\n",
       "      <td>0.938873</td>\n",
       "      <td>0.753977</td>\n",
       "      <td>0.657961</td>\n",
       "      <td>0.516219</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
