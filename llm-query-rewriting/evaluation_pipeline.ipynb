{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "753a05bdc7331ed0",
   "metadata": {},
   "source": [
    "# Information Retrieval Evaluation Pipeline\n",
    "This notebook provides a template for evaluating query reformulation techniques using PyTerrier.\n",
    "Pipeline stages: Dataset Loading → Preprocessing → Query Reformulation → Retrieval → Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d3d067a6d763",
   "metadata": {},
   "source": [
    "## 1. Dataset Loading\n",
    "This can be switched with another dataset, possibly requiring conversion to this format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db121cb9c9ddcc18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:51:25.855659Z",
     "start_time": "2025-03-31T09:51:15.213151Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] https://raw.githubusercontent.com/grill-lab/CODEC/main/raw_judgments/raw_document_judgments.txt\n",
      "                                                        \n",
      "\u001b[A                                                                                                                             [INFO] [finished] https://raw.githubusercontent.com/grill-lab/CODEC/main/raw_judgments/raw_document_judgments.txt: [00:00] [307kB] [11.2MB/s]\n",
      "Generating qrels split: 6186 examples [00:00, 7490.68 examples/s]\n",
      "[INFO] [starting] https://raw.githubusercontent.com/grill-lab/CODEC/main/topics/topics.json\n",
      "                                                          \n",
      "\u001b[A                                                                                                        [INFO] [finished] https://raw.githubusercontent.com/grill-lab/CODEC/main/topics/topics.json: [00:00] [47.2kB] [18.8MB/s]\n",
      "Generating queries split: 42 examples [00:00, 127.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "class DatasetComponents:\n",
    "    \"\"\"Container for dataset components that must be provided\"\"\"\n",
    "    def __init__(self, corpus_iter, queries_df, qrels_df):\n",
    "        self.corpus_iter = corpus_iter  # Iterator yielding {'docno': str, 'text': str}\n",
    "        self.queries_df = queries_df    # DataFrame with columns ['qid', 'query']\n",
    "        self.qrels_df = qrels_df        # DataFrame with columns ['qid', 'docno', 'label']\n",
    "\n",
    "def load_pt_dataset():\n",
    "    \"\"\"Load codec dataset\"\"\"\n",
    "    docs = load_dataset(\"macavaney/codec\")[\"train\"]\n",
    "    qrels = load_dataset('irds/codec', 'qrels', trust_remote_code=True)\n",
    "    queries = load_dataset('irds/codec', 'queries', trust_remote_code=True)\n",
    "\n",
    "    # Convert dataset to correct format\n",
    "    corpus_iter = ({'docno': str(doc['id']), 'text': doc['contents']} for doc in docs)\n",
    "\n",
    "    queries_df = pd.DataFrame(queries)[['query_id', 'query']]\n",
    "    queries_df.columns = ['qid', 'query']\n",
    "\n",
    "    qrels_df = pd.DataFrame(qrels)[['query_id', 'doc_id', 'relevance']]\n",
    "    qrels_df.columns = ['qid', 'docno', 'label']\n",
    "\n",
    "    return DatasetComponents(corpus_iter, queries_df, qrels_df)\n",
    "\n",
    "# Load the dataset\n",
    "data = load_pt_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6430c8a33bc386",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Pipeline\n",
    "Currently, this does no preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad9172b403521b3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:54:52.151562Z",
     "start_time": "2025-03-31T09:54:50.647083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n"
     ]
    }
   ],
   "source": [
    "if not pt.java.started():\n",
    "    pt.java.init()\n",
    "\n",
    "tokeniser = pt.java.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n",
    "def strip_markup(text):\n",
    "    return \" \".join(tokeniser.getTokens(text))\n",
    "\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Placeholder for text preprocessing logic\"\"\"\n",
    "    return text\n",
    "\n",
    "def preprocess_corpus(corpus_iter):\n",
    "    \"\"\"Generator that applies preprocessing to each document\"\"\"\n",
    "    for doc in corpus_iter:\n",
    "        yield {\n",
    "            'docno': doc['docno'],\n",
    "            'text': preprocess_text(doc['text'])\n",
    "        }\n",
    "\n",
    "def preprocess_queries(queries_df):\n",
    "    \"\"\"Apply preprocessing to queries dataframe\"\"\"\n",
    "    queries_df = queries_df.copy()\n",
    "    queries_df['query'] = queries_df['query'].apply(strip_markup)\n",
    "    return queries_df\n",
    "\n",
    "# Apply preprocessing while maintaining iterator\n",
    "preprocessed_corpus = preprocess_corpus(data.corpus_iter)\n",
    "preprocessed_queries = preprocess_queries(data.queries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56384466c733ca6",
   "metadata": {},
   "source": [
    "## 3. Indexing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cdc0163f153be40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:54:56.761654Z",
     "start_time": "2025-03-31T09:54:56.756575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building new index...\n",
      "21:25:04.530 [main] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (33fe4e1497ca8722bb0b16ee857c2e95) - further warnings are suppressed\n",
      "21:45:23.045 [main] ERROR org.terrier.structures.indexing.Indexer -- Could not finish MetaIndexBuilder: \n",
      "java.io.IOException: Key 282f6a4a77e8a8c989e9d72038177201 is not unique: 507572,477277\n",
      "For MetaIndex, to suppress, set metaindex.compressed.reverse.allow.duplicates=true\n",
      "\tat org.terrier.structures.collections.FSOrderedMapFile$MultiFSOMapWriter.mergeTwo(FSOrderedMapFile.java:1374)\n",
      "\tat org.terrier.structures.collections.FSOrderedMapFile$MultiFSOMapWriter.close(FSOrderedMapFile.java:1308)\n",
      "\tat org.terrier.structures.indexing.BaseMetaIndexBuilder.close(BaseMetaIndexBuilder.java:321)\n",
      "\tat org.terrier.structures.indexing.classical.BasicIndexer.indexDocuments(BasicIndexer.java:270)\n",
      "\tat org.terrier.structures.indexing.classical.BasicIndexer.createDirectIndex(BasicIndexer.java:388)\n",
      "\tat org.terrier.structures.indexing.Indexer.index(Indexer.java:377)\n",
      "21:46:47.032 [main] WARN org.terrier.structures.indexing.Indexer -- Indexed 1 empty documents\n",
      "Built new index at c:\\Users\\alexp\\Desktop\\InformationRetrieval\\llm-query-rewriting\\index\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'org.terrier.querying.IndexRef' object has no attribute 'getCollectionStatistics'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     23\u001b[39m index_ref = pt.index.IterDictIndexer(\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mstr\u001b[39m(index_path),\n\u001b[32m     25\u001b[39m     meta={\u001b[33m\"\u001b[39m\u001b[33mdocno\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m32\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m131072\u001b[39m},\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mtype\u001b[39m=pt.index.IndexingType.CLASSIC\n\u001b[32m     27\u001b[39m ).index(preprocessed_corpus)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBuilt new index at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mindex_ref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetCollectionStatistics\u001b[49m())\n",
      "\u001b[31mAttributeError\u001b[39m: 'org.terrier.querying.IndexRef' object has no attribute 'getCollectionStatistics'"
     ]
    }
   ],
   "source": [
    "index_path = Path.cwd() / \"index\"\n",
    "index_ref = None\n",
    "\n",
    "# Check if valid index exists\n",
    "if (index_path / \"data.properties\").exists():\n",
    "    try:\n",
    "        index_ref = pt.IndexFactory.of(str(index_path))\n",
    "        print(f\"Loaded existing index from {index_path}\")\n",
    "\n",
    "        # Verify index contains documents\n",
    "        if index_ref.getCollectionStatistics().getNumberOfDocuments() == 0:\n",
    "            raise ValueError(\"Empty index - will rebuild\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Index loading failed ({str(e)}), rebuilding...\")\n",
    "        import shutil\n",
    "        shutil.rmtree(index_path)\n",
    "        index_ref = None\n",
    "\n",
    "# Build new index if needed\n",
    "if index_ref is None:\n",
    "    print(\"Building new index...\")\n",
    "    index_ref = pt.index.IterDictIndexer(\n",
    "        str(index_path),\n",
    "        meta={\"docno\": 32, \"text\": 131072},\n",
    "        type=pt.index.IndexingType.CLASSIC\n",
    "    ).index(preprocessed_corpus)\n",
    "    print(f\"Built new index at {index_path}\")\n",
    "\n",
    "    print(index_ref.getCollectionStatistics())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883dae17c944c37e",
   "metadata": {},
   "source": [
    "## 4. Query Reformulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14c6f38522030fbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:55:00.767751Z",
     "start_time": "2025-03-31T09:55:00.141765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:30:47.937 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.4 GiB of memory would be required.\n",
      "22:30:48.186 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.4 GiB of memory would be required.\n",
      "22:30:58.133 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.4 GiB of memory would be required.\n",
      "22:30:58.358 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.4 GiB of memory would be required.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import classic_rewriting\n",
    "importlib.reload(classic_rewriting)\n",
    "\n",
    "def reformulate_queries_rm3(queries_df, index_ref):\n",
    "    \"\"\"Reformulate queries using RM3\"\"\"\n",
    "    modified_queries = queries_df.copy()\n",
    "\n",
    "    # Use RM3 for query expansion\n",
    "    modified_queries = classic_rewriting.rewrite_queries_RM3(modified_queries, index_ref)\n",
    "    \n",
    "    # If you want to replace the original queries with expanded ones\n",
    "    if 'expanded_query' in modified_queries.columns:\n",
    "        modified_queries['query'] = modified_queries['expanded_query']\n",
    "        modified_queries = modified_queries.drop(columns=['expanded_query'])\n",
    "\n",
    "    return modified_queries\n",
    "\n",
    "def reformulate_queries_bo1(queries_df, index_ref):\n",
    "    \"\"\"Reformulate queries using BO1\"\"\"\n",
    "    modified_queries = queries_df.copy()\n",
    "\n",
    "    # Use BO1 for query expansion\n",
    "    modified_queries = classic_rewriting.rewrite_queries_BO1(modified_queries, index_ref)\n",
    "    \n",
    "    # If you want to replace the original queries with expanded ones\n",
    "    if 'expanded_query' in modified_queries.columns:\n",
    "        modified_queries['query'] = modified_queries['expanded_query']\n",
    "        modified_queries = modified_queries.drop(columns=['expanded_query'])\n",
    "\n",
    "    return modified_queries\n",
    "\n",
    "reformulated_queries_rm3 = reformulate_queries_rm3(preprocessed_queries, index_ref)\n",
    "reformulated_queries_bo1 = reformulate_queries_bo1(preprocessed_queries, index_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9d95b751b558b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:57:06.425059Z",
     "start_time": "2025-03-31T09:57:06.410989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 729824\n",
      "Number of terms: 941881\n",
      "Number of postings: 159765825\n",
      "Number of fields: 0\n",
      "Number of tokens: 273318564\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802bf1529629a611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:51:27.118136800Z",
     "start_time": "2025-03-28T15:00:10.924155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted index at C:\\Users\\thein\\OneDrive\\Documents\\InformationRetrieval\\llm-query-rewriting\\index\n"
     ]
    }
   ],
   "source": [
    "# Function to delete the index in case it should be recreated\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def delete_index(index_path):\n",
    "    \"\"\"Deletes the index at the specified path.\"\"\"\n",
    "    if index_path.exists():\n",
    "        shutil.rmtree(index_path)\n",
    "        print(f\"Deleted index at {index_path}\")\n",
    "    else:\n",
    "        print(\"No index found to delete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6500474760e53a52",
   "metadata": {},
   "source": [
    "## 5. Retrieval Setup\n",
    "Currently, using BM25 for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf327eb8457b516",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:57:59.429239Z",
     "start_time": "2025-03-31T09:57:59.387452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexp\\AppData\\Local\\Temp\\ipykernel_11164\\1263414164.py:1: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  bm25 = pt.BatchRetrieve(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:15:34.237 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.4 GiB of memory would be required.\n"
     ]
    }
   ],
   "source": [
    "bm25 = pt.BatchRetrieve(\n",
    "    index_ref,\n",
    "    wmodel=\"BM25\",\n",
    "    metadata=[\"docno\", \"text\"],\n",
    "    properties={\"termpipelines\": \"\"},\n",
    "    controls={\"qe\": \"off\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acbe90722ed77a3",
   "metadata": {},
   "source": [
    "## 6. Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164eee1c656fe26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T10:13:01.595068Z",
     "start_time": "2025-03-31T10:11:34.904845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for no query reformulation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>P_10</th>\n",
       "      <th>recall_100</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>map +</th>\n",
       "      <th>map -</th>\n",
       "      <th>map p-value</th>\n",
       "      <th>recip_rank +</th>\n",
       "      <th>recip_rank -</th>\n",
       "      <th>recip_rank p-value</th>\n",
       "      <th>P_10 +</th>\n",
       "      <th>P_10 -</th>\n",
       "      <th>P_10 p-value</th>\n",
       "      <th>recall_100 +</th>\n",
       "      <th>recall_100 -</th>\n",
       "      <th>recall_100 p-value</th>\n",
       "      <th>ndcg_cut_10 +</th>\n",
       "      <th>ndcg_cut_10 -</th>\n",
       "      <th>ndcg_cut_10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>BM25 Baseline</td>\n",
       "      <td>0.284473</td>\n",
       "      <td>0.800519</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.401966</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for reformulated queries using RM3:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>P_10</th>\n",
       "      <th>recall_100</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>map +</th>\n",
       "      <th>map -</th>\n",
       "      <th>map p-value</th>\n",
       "      <th>recip_rank +</th>\n",
       "      <th>recip_rank -</th>\n",
       "      <th>recip_rank p-value</th>\n",
       "      <th>P_10 +</th>\n",
       "      <th>P_10 -</th>\n",
       "      <th>P_10 p-value</th>\n",
       "      <th>recall_100 +</th>\n",
       "      <th>recall_100 -</th>\n",
       "      <th>recall_100 p-value</th>\n",
       "      <th>ndcg_cut_10 +</th>\n",
       "      <th>ndcg_cut_10 -</th>\n",
       "      <th>ndcg_cut_10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>BM25 with RM3</td>\n",
       "      <td>0.30453</td>\n",
       "      <td>0.73106</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.379398</td>\n",
       "      <td>0.374728</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for reformulated queries using BO1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>P_10</th>\n",
       "      <th>recall_100</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>map +</th>\n",
       "      <th>map -</th>\n",
       "      <th>map p-value</th>\n",
       "      <th>recip_rank +</th>\n",
       "      <th>recip_rank -</th>\n",
       "      <th>recip_rank p-value</th>\n",
       "      <th>P_10 +</th>\n",
       "      <th>P_10 -</th>\n",
       "      <th>P_10 p-value</th>\n",
       "      <th>recall_100 +</th>\n",
       "      <th>recall_100 -</th>\n",
       "      <th>recall_100 p-value</th>\n",
       "      <th>ndcg_cut_10 +</th>\n",
       "      <th>ndcg_cut_10 -</th>\n",
       "      <th>ndcg_cut_10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>BM25 with BO1</td>\n",
       "      <td>0.322746</td>\n",
       "      <td>0.822587</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>0.402822</td>\n",
       "      <td>0.429287</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run evaluation experiment\n",
    "# metrics: https://pyterrier.readthedocs.io/en/latest/experiments.html#available-evaluation-measures\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Alternative import approaches\n",
    "try:\n",
    "    # Try the standard import first\n",
    "    from IPython.display import display, HTML\n",
    "except ImportError:\n",
    "    # Fallback options\n",
    "    try:\n",
    "        from IPython import display\n",
    "        HTML = display.HTML\n",
    "    except ImportError:\n",
    "        # If IPython display isn't working, define a simple fallback\n",
    "        def display(obj):\n",
    "            print(obj)\n",
    "        \n",
    "        class HTML:\n",
    "            def __init__(self, html_str):\n",
    "                self.html = html_str\n",
    "            \n",
    "            def _repr_html_(self):\n",
    "                return self.html\n",
    "\n",
    "\n",
    "# Directory containing JSON files\n",
    "results_dir = \"./results\"\n",
    "\n",
    "# Evaluation metrics\n",
    "eval_metrics = [\"map\", \"ndcg_cut_10\", \"P_10\", \"recall_100\", \"recip_rank\"]\n",
    "\n",
    "results = pt.Experiment(\n",
    "    [bm25],\n",
    "    preprocessed_queries,\n",
    "    data.qrels_df,\n",
    "    eval_metrics,\n",
    "    names=[\"BM25 Baseline\"],\n",
    "    baseline=0\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(\"Results for no query reformulation:\")\n",
    "display(HTML(results.to_html(index=False)))\n",
    "\n",
    "# Display the results for reformulated queries\n",
    "print(\"Results for reformulated queries using RM3:\")\n",
    "results_reformulated = pt.Experiment(\n",
    "    [bm25],\n",
    "    reformulated_queries_rm3,\n",
    "    data.qrels_df,\n",
    "    eval_metrics,\n",
    "    names=[\"BM25 with RM3\"],\n",
    "    baseline=0\n",
    ")\n",
    "display(HTML(results_reformulated.to_html(index=False)))\n",
    "\n",
    "# Display the results for reformulated queries\n",
    "print(\"Results for reformulated queries using BO1:\")\n",
    "results_reformulated = pt.Experiment(\n",
    "    [bm25],\n",
    "    reformulated_queries_bo1,\n",
    "    data.qrels_df,\n",
    "    eval_metrics,\n",
    "    names=[\"BM25 with BO1\"],\n",
    "    baseline=0\n",
    ")\n",
    "display(HTML(results_reformulated.to_html(index=False)))\n",
    "\n",
    "\n",
    "# Loop through JSON files in the directory\n",
    "for filename in os.listdir(results_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(results_dir, filename)\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data_json = json.load(f)\n",
    "\n",
    "            # Convert JSON data to DataFrame\n",
    "            queries_df = pd.DataFrame(data_json)[[\"query_id\", \"query_rewrite\"]]\n",
    "            queries_df.columns = [\"qid\", \"query\"]\n",
    "            queries_df['query'] = queries_df['query'].apply(strip_markup)\n",
    "\n",
    "            print(f\"Processing file: {filename}\")\n",
    "\n",
    "            results = pt.Experiment(\n",
    "                [bm25],\n",
    "                queries_df,\n",
    "                data.qrels_df,\n",
    "                eval_metrics,\n",
    "                names=[\"BM25 Baseline\"],\n",
    "                baseline=0\n",
    "            )\n",
    "\n",
    "            # Display the results\n",
    "            display(HTML(results.to_html(index=False)))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
